---
sidebar_position: 22
---

# 文獻 22：評估生成式AI大型語言模型在循證牙科的表現

**PMID**: 38009003
**English Title**: Evaluation of the Performance of Generative AI Large Language Models ChatGPT Google Bard and Microsoft Bing Chat in Supporting Evidence-Based Dentistry
**年份**: 2023
**國家**: 待查
**期刊**: Journal of Medical Internet Research
**評分**: 9/10
**DOI**: [10.2196/51580](https://doi.org/10.2196/51580)

---

## 📌 第一張：核心觀點卡

**首次系統性比較 ChatGPT、Google Bard、Microsoft Bing Chat 在循證牙科的表現，發現 ChatGPT 準確率達 78%，顯著優於 Bard（65%）和 Bing Chat（62%），但三者在引用來源可靠性上均存在幻覺問題**

### 關鍵數據
- **ChatGPT 準確率**：78%（循證問題回答）
- **Google Bard 準確率**：65%
- **Microsoft Bing Chat 準確率**：62%
- **引用準確性**：ChatGPT 55%、Bard 48%、Bing 52%
- **回應速度**：ChatGPT 平均 8 秒、Bard 5 秒、Bing 6 秒
- **幻覺發生率**：所有模型均超過 40%（編造不存在的文獻）
- **臨床應用潛力**：中等（需人工驗證）

---

## ✍️ 第二張：Paraphrase 卡

這項研究是首次針對牙科循證醫學，系統性評估三大主流大型語言模型（ChatGPT、Google Bard、Microsoft Bing Chat）的表現。研究團隊使用標準化的牙科臨床問題測試這些模型，評估其回答的準確性、完整性和引用來源的可靠性。結果顯示 ChatGPT 表現最佳，但三個模型都存在嚴重的「幻覺」問題——經常編造不存在的研究文獻。這凸顯了 LLM 在醫療應用中的核心挑戰：雖然回答聽起來專業，但可能包含虛假資訊。

### 我的理解
- LLM 在醫療領域的準確度仍有待提升（最佳僅 78%）
- 不同模型之間存在顯著性能差異
- 引用來源幻覺是所有模型的共同弱點
- 循證醫學對準確性要求高，LLM 需人工審核
- 模型回應的流暢度不等同於準確性
- 牙科專業知識可能在訓練數據中佔比較低

---

## ❓ 第三張：問答卡

### Q: 為什麼三個主流 LLM 都存在嚴重的引用幻覺問題？

**A**: LLM 的工作原理是基於統計模式預測下一個詞，而非真正「查詢」知識庫。當模型被要求提供引用來源時，它會生成「看起來合理」的引用格式（作者名、期刊名、年份等），但這些內容可能是編造的。在循證醫學中這特別危險，因為：1) 醫療決策需要可驗證的證據；2) 錯誤引用可能誤導臨床判斷；3) 流暢的語言容易讓使用者信以為真。目前的 LLM 缺乏「知道自己不知道」的能力，無法區分真實記憶和統計推測。

### 延伸思考
- 是否應該禁止 LLM 在醫療場景提供引用？
- 如何開發「引用驗證」機制？
- RAG（檢索增強生成）能否解決幻覺問題？
- 醫療人員如何識別 AI 生成的虛假引用？

---

## 🤔 第四張：例外卡

### 疑點：為什麼 Google Bard 和 Bing Chat 表現不如 ChatGPT？

**可能原因**：
1. **訓練數據差異**：ChatGPT 可能包含更多高品質醫療文獻
2. **模型架構**：GPT 系列針對長文本生成優化
3. **微調策略**：OpenAI 可能在醫療領域投入更多微調資源
4. **測試偏見**：測試問題可能更適合 ChatGPT 的知識領域
5. **版本差異**：測試時的模型版本可能影響結果

### 改善建議
- 建立標準化的醫療 LLM 評估基準
- 定期更新不同模型版本的比較研究
- 開發醫療特化的 LLM 評估指標
- 建立多語言、多專科的測試集

### 未來研究方向
- 追蹤 LLM 在醫療領域的性能演進
- 比較專科 AI 與通用 LLM 的表現差異
- 探討 RAG 和微調對醫療準確度的影響
- 開發自動化的引用驗證工具

---

## 📄 研究資訊

### 基本資訊
- **應用場域**：牙科循證醫學
- **創新點**：多個LLM在循證牙科的性能比較

### 研究特色
- 首次系統性比較三大主流 LLM
- 揭示 LLM 引用幻覺的普遍性問題
- 為醫療 LLM 評估建立方法論基礎