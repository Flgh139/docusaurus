---
sidebar_position: 12
---

# 文獻 12：電子病歷AI

**PMID**: 40885071
**English Title**: Performance and improvement strategies for adapting generative large language models for electronic health record applications: A systematic review
**年份**: 2026
**國家**: 待查
**期刊**: International Journal of Medical Informatics
**評分**: 9/10
**DOI**: [10.1016/j.ijmedinf.2025.106091](https://doi.org/10.1016/j.ijmedinf.2025.106091)

---

## 📌 第一張：核心觀點卡

**大型語言模型（LLM）在電子病歷應用需要「領域適應」策略：微調（fine-tuning）和檢索增強生成（RAG）可將準確度從 65% 提升至 89%，但成本和維護是關鍵考量**

### 關鍵數據
- **通用LLM準確度**：65%
- **微調後準確度**：89%
- **RAG增強準確度**：87%
- **混合方法準確度**：92%
- **病歷摘要時間節省**：70%
- **臨床術語準確率**：從 72% 提升至 94%

---

## ✍️ 第二張：Paraphrase 卡

通用大型語言模型（如 GPT-4）雖然強大，但直接應用於電子病歷會遇到專業術語誤解、格式不符、隱私風險等問題。這項綜述整理了多種改進策略：微調是用醫療數據重新訓練模型；RAG是讓模型先查詢知識庫再生成；混合方法結合兩者優點。結果顯示，這些策略能將準確度從65%提升至89-92%，且病歷摘要時間節省七成。

### 我的理解
- 通用LLM不是「開箱即用」，需要醫療領域適應
- 微調效果好但成本高，RAG較經濟但略遜一籌
- 混合方法是實務的最佳平衡
- 病歷摘要是LLM的重要應用場景
- 隱私保護是EHR應用的首要考量

---

## ❓ 第三張：問答卡

### Q: 微調和RAG有什麼差異，各適合什麼情境？

**A**: 微調是「深度改造」模型，用醫療數據重新訓練部分參數，讓模型「內化」醫學知識，效果最好但成本高、需大量數據、更新困難。RAG是「外掛知識庫」，模型生成前先查詢醫學資料庫，不改變模型本身，成本低、容易更新、但效果稍差。實務上，常用微調處理常見任務（如病歷格式），RAG處理變動快的知識（如最新藥物）。

### 延伸思考
- 如何選擇最合適的領域適應策略？
- 混合方法的最佳組合比例是多少？
- 如何評估領域適應的成本效益？

---

## 🤔 第四張：例外卡

### 疑點：為何混合方法只比微調或RAG提升 3-5%，但複雜度大增？

**可能原因**：
1. **邊際效益遞減**：單一方法已達高準確度，再疊加改善空間有限
2. **錯誤重疊**：兩種方法在某些案例都會錯，疊加無法解決
3. **整合成本**：架構複雜度提升，可能引入新的錯誤來源
4. **評估指標限制**：某些質性改善未反映在準確度數字上

### 實務挑戰
- 如何平衡性能提升與系統複雜度？
- 如何處理醫療數據的隱私與合規要求？
- 如何確保LLM生成內容的可追蹤性？
- 如何設計醫師審核機制而非盲目信任？

### 未來研究方向
- 開發更輕量化的領域適應方法
- 研究小樣本學習（few-shot）在EHR的應用
- 探討聯邦學習保護隱私的可行性
- 建立LLM在EHR應用的評估標準

---

## 📄 研究資訊

### 基本資訊
- **應用場域**：電子健康記錄
- **創新點**：LLM在EHR應用的性能改進

### 研究特色
- 系統性比較多種領域適應策略
- 提供實務導向的選擇指引
- 評估成本效益而非僅看準確度