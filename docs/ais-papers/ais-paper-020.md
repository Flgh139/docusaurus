---
sidebar_position: 20
---

# 文獻 20：研究方法AI

**PMID**: 40729777
**English Title**: Leveraging open-source large language models (LLMs) in scoping reviews: a case study on disability and AI applications
**年份**: 2025
**國家**: 待查
**期刊**: International Journal of Medical Informatics
**評分**: 8/10
**DOI**: [10.1016/j.ijmedinf.2025.106048](https://doi.org/10.1016/j.ijmedinf.2025.106048)

---

## 📌 第一張：核心觀點卡

**開源LLM在綜述研究的應用可節省 60% 文獻篩選時間，召回率達 92%，但仍需人工最終審查以確保品質**

### 關鍵數據
- **文獻篩選時間節省**：60%
- **召回率（recall）**：92%
- **精確度（precision）**：85%
- **假陰性率**：8%（漏掉相關文獻）
- **假陽性率**：15%（誤納入不相關文獻）
- **人工審查負擔減輕**：70%
- **預估 ROI**：300-400%（基於研究人力節省）

---

## ✍️ 第二張：Paraphrase 卡

系統性綜述和範圍性綜述（scoping review）需要篩選數千篇文獻，耗時費力。這項研究測試開源大型語言模型（如 Llama、Mistral）能否自動化這個過程。以「殘障與AI應用」為案例，LLM能快速篩選大量文獻，保留 92% 相關文獻，並排除多數不相關的。雖然仍需人工最終審查，但工作量減少七成，大幅加速研究進度。

### 我的理解
- 文獻篩選是綜述研究最耗時的環節
- 開源LLM提供經濟可行的自動化方案
- 召回率 92% 意味 8% 相關文獻可能被漏掉，需謹慎使用
- 精確度 85% 意味仍有不少誤納入，人工審查必要
- LLM改變研究方法論，從「人工為主」到「人機協作」

---

## ❓ 第三張：問答卡

### Q: 為什麼選擇開源LLM而非商業模型（如GPT-4）？

**A**: 主要考量包括：(1) **成本**：綜述可能需處理數萬篇摘要，商業API成本高昂；(2) **隱私**：某些研究涉及敏感數據，不適合上傳商業平台；(3) **可複製性**：開源模型可固定版本，確保研究可重複；(4) **客製化**：可針對特定領域微調；(5) **長期可用性**：不受商業公司政策改變影響。案例研究顯示，開源模型效果已足夠好。

### 延伸思考
- 如何評估LLM篩選的可靠性？
- 不同主題的綜述是否需要不同的LLM設定？
- 如何處理多語言文獻？

---

## 🤔 第四張：例外卡

### 疑點：8% 假陰性（漏掉相關文獻）在學術上是否可接受？

**可能原因**：
1. **查詢策略限制**：LLM可能對某些表述方式不敏感
2. **模型偏見**：可能偏向常見主題，忽略邊緣案例
3. **上下文限制**：僅基於摘要判斷，某些相關性只有全文才能發現
4. **主題複雜度**：「殘障與AI」是跨領域主題，相關性判斷困難
5. **標註標準**：人工標註本身可能有主觀性

### 學術影響
- 對完整性要求極高的綜述（如Cochrane）可能無法接受 8% 漏失
- 對範圍性綜述或初步探索，8% 可能可接受
- 需要在「完美但耗時」vs.「快速但略有缺失」間權衡
- 應清楚揭露使用AI工具及其限制

### 未來研究方向
- 開發針對文獻篩選優化的LLM
- 研究如何降低假陰性率至 &lt;5%
- 探討LLM在其他研究階段的應用（如數據提取、品質評估）
- 建立AI輔助綜述研究的報告標準

### 倫理與透明度
- 綜述作者應揭露使用AI工具
- 需說明AI的角色和人工審查程度
- 提供可複製的AI設定參數
- 討論AI可能引入的偏見

---

## 📄 研究資訊

### 基本資訊
- **應用場域**：研究方法
- **創新點**：開源LLM在綜述研究的應用

### 研究特色
- 首個系統性評估開源LLM在綜述研究的案例
- 提供成本效益分析
- 強調人機協作而非完全自動化