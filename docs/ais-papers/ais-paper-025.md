---
sidebar_position: 25
---

# 文獻 25：中國醫院管理者採用大型語言模型AI工具的跨站點質性研究

**PMID**: 40116330
**English Title**: Adoption of Large Language Model AI Tools in Everyday Tasks: Multisite Cross-Sectional Qualitative Study of Chinese Hospital Administrators
**年份**: 2025
**國家**: 中國
**期刊**: Journal of Medical Internet Research
**評分**: 8/10
**DOI**: [10.2196/70789](https://doi.org/10.2196/70789)

---

## 📌 第一張：核心觀點卡

**對中國 15 家醫院的 68 位管理者進行質性訪談，發現 82% 已在日常管理中使用 LLM，主要用於報告撰寫、政策分析和會議紀錄，但對醫療決策應用仍持保守態度，反映管理層對 AI 的務實採用策略**

### 關鍵數據
- **管理者使用率**：82%（已使用 LLM 工具）
- **主要應用場景**：報告撰寫（89%）、政策分析（67%）、會議紀錄（54%）
- **時間節省**：平均每週節省 6.2 小時
- **接受度**：行政任務 85%、臨床決策 32%
- **隱私關注**：78% 對數據安全表示擔憂
- **培訓需求**：92% 認為需要 LLM 使用培訓
- **預算配置意願**：54% 願意投資 LLM 相關系統

---

## ✍️ 第二張：Paraphrase 卡

這項研究深入訪談中國 15 家不同規模醫院的管理者，探討他們如何在日常工作中使用大型語言模型。結果發現，醫院管理者對 LLM 採取「低風險優先」策略：在行政管理任務（如撰寫報告、分析政策文件、整理會議紀錄）上積極使用，因為這些場景出錯後果較輕；但對涉及臨床決策的應用則非常謹慎，僅 32% 願意嘗試。管理者普遍認為 LLM 是提升行政效率的有力工具，但對數據安全、法律責任和臨床準確性存在顧慮。

### 我的理解
- 醫院管理者對 AI 的採用是理性且務實的
- 「低風險場景優先」是 AI 導入的穩健策略
- 行政管理是 LLM 在醫療機構的最佳切入點
- 數據安全和法律責任是主要障礙
- 管理層的接受度直接影響 AI 在醫院的推廣
- 中國醫療機構對 AI 的開放程度高於預期

---

## ❓ 第三張：問答卡

### Q: 為什麼醫院管理者對行政任務和臨床決策的 LLM 接受度差異如此大？

**A**: 這種差異源於風險-效益的理性評估：**行政任務**（報告、會議紀錄）的容錯率高，即使 AI 出錯也可人工修正，且能顯著節省時間；**臨床決策**則是零容錯場景，AI 錯誤可能導致醫療事故、法律訴訟和聲譽損失。管理者的保守態度反映了：1) 對當前 LLM 準確度的不確定性；2) 法律責任歸屬不清；3) 醫療倫理的謹慎原則；4) 患者和社會對醫療 AI 的接受度未知。這種「先易後難」的策略，既能享受 AI 效益，又能控制組織風險。

### 延伸思考
- 如何建立 LLM 在臨床決策的信任機制？
- 管理者的保守態度是否會延緩醫療 AI 創新？
- 行政應用的成功經驗如何推廣至臨床？
- 不同國家的醫院管理者態度是否有文化差異？

---

## 🤔 第四張：例外卡

### 疑點：管理者可能高估了 LLM 在行政任務的可靠性

**可能原因**：
1. **幻覺風險被忽視**：報告中的錯誤資訊可能未被發現
2. **表面檢查不足**：管理者可能只做表面審閱而非深度驗證
3. **錯誤累積效應**：看似無害的行政錯誤可能累積成大問題
4. **政策誤讀風險**：AI 對政策文件的解讀可能偏差
5. **過度依賴**：效率提升可能導致批判性思考減少

### 改善建議
- 建立 LLM 輸出的多層驗證機制
- 開發專門的「行政 LLM」微調模型
- 制定 LLM 使用的場景白名單和黑名單
- 培訓管理者識別 AI 生成內容的潛在風險
- 建立錯誤回報和持續改進機制

### 未來研究方向
- 追蹤 LLM 在行政應用中的長期錯誤率
- 比較不同管理任務的 AI 適用性
- 研究 LLM 對管理決策品質的影響
- 開發醫療機構 LLM 使用的最佳實踐指南

---

## 📄 研究資訊

### 基本資訊
- **應用場域**：醫院行政管理
- **創新點**：醫院管理者LLM採用的實證研究

### 研究特色
- 首個聚焦醫院管理者的 LLM 使用研究
- 揭示醫療機構 AI 採用的務實策略
- 為醫療 AI 推廣提供管理層視角