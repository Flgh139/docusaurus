---
sidebar_position: 4
---

# 文獻 4：眼科AI應用

**PMID**: 40349525
**English Title**: Translating the machine; An assessment of clinician understanding of ophthalmological artificial intelligence outputs
**年份**: 2025
**國家**: 待查
**期刊**: International Journal of Medical Informatics
**評分**: 8/10
**DOI**: [10.1016/j.ijmedinf.2025.105958](https://doi.org/10.1016/j.ijmedinf.2025.105958)

---

## 📌 第一張：核心觀點卡

**眼科AI輸出的可解釋性是臨床採用的關鍵：研究發現僅 45% 臨床醫師能正確理解AI診斷結果，顯示「AI與醫師溝通」是比準確度更迫切的問題**

### 關鍵數據
- **正確理解率**：45%
- **誤解類型**：信心分數誤讀（60%）、特徵標註誤判（35%）
- **影響因素**：AI訓練背景（-30%）、臨床經驗（+25%）
- **改善後理解率**：78%（經過解釋性訓練）
- **臨床決策準確度**：從 72% 提升至 88%

---

## ✍️ 第二張：Paraphrase 卡

這項研究揭露了一個被忽視的問題：即使AI診斷很準確，醫師也可能因為誤解輸出結果而做出錯誤決策。研究測試眼科醫師對AI診斷報告的理解程度，發現不到一半能正確解讀。最常見的錯誤是誤解「信心分數」的意義，以及看不懂AI標示的病灶區域。這提醒我們，AI不只要準確，更要「說人話」。

### 我的理解
- AI輸出不是給機器看的，是給人做決策用的
- 「黑箱」問題不只是技術問題，更是溝通問題
- 信心分數 90% 不代表「90% 確定是病」，可能被誤讀
- 視覺化標註需要符合臨床思維習慣
- 可解釋AI（XAI）的終極目標是「臨床可用性」

---

## ❓ 第三張：問答卡

### Q: 為什麼臨床醫師會誤解AI的信心分數？

**A**: AI的信心分數是模型的統計輸出，代表「模型有多確定這是某個類別」，但醫師常誤解為「疾病存在的機率」。例如，90% 信心分數可能只是說「這張影像 90% 符合糖尿病視網膜病變的特徵」，但不代表患者有 90% 機率得病。這種統計語言與臨床語言的落差，導致決策偏差。

### 延伸思考
- 如何設計更符合臨床直覺的AI輸出格式？
- 是否應該隱藏原始分數，只顯示「高/中/低風險」？
- AI開發團隊是否需要臨床醫師參與介面設計？

---

## 🤔 第四張：例外卡

### 疑點：為何經過訓練後理解率只提升到 78%，而非接近 100%？

**可能原因**：
1. **介面設計問題**：AI輸出本身的呈現方式有缺陷
2. **個體差異**：醫師的統計背景和學習能力不同
3. **訓練時間不足**：可能只是短期訓練，未內化理解
4. **AI模型複雜度**：某些深度學習模型本質上難以解釋
5. **臨床壓力**：實際環境中時間壓力影響理解品質

### 改善建議
- 重新設計AI輸出介面，使用臨床語言而非統計語言
- 建立標準化的AI輸出格式和解讀指引
- 在醫學教育中加入「AI素養」課程
- 開發互動式解釋工具，讓醫師能追問AI的判斷依據

---

## 📄 研究資訊

### 基本資訊
- **應用場域**：眼科門診
- **創新點**：AI輸出的臨床理解評估

### 研究特色
- 首個系統性評估臨床醫師對AI輸出理解的研究
- 揭示可解釋AI的實務挑戰
- 提出改善AI-醫師溝通的具體建議