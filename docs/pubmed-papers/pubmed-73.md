---
sidebar_position: 73
---

# æ–‡ç» 73ï¼šFrom dictation to diagnosis: enhancing radiology reporting with integrated speech recognition

**English Title**: From dictation to diagnosis: enhancing radiology reporting with integrated speech recognition

**ä¸­æ–‡æ¨™é¡Œ**: å¾è½å¯«åˆ°è¨ºæ–·ï¼šé€šéé›†æˆèªéŸ³è­˜åˆ¥å¢å¼·æ”¾å°„å­¸å ±å‘Š
**PMID**: 40815310
**æœŸåˆŠ**: æœªçŸ¥æœŸåˆŠ
**è©•åˆ†**: é«˜
**æ‡‰ç”¨é ˜åŸŸ**: 9
**DOI**: https://doi.org/10.1007/s00330-025-11929-y

---

## ğŸ“Œ ç¬¬ä¸€å¼µï¼šæ ¸å¿ƒè§€é»å¡

### ä¸»è¦ç™¼ç¾
é«˜

### æ–‡ç»æ‘˜è¦ï¼ˆAbstractï¼‰
OBJECTIVES: This study evaluates the efficiency, accuracy, and cost-effectiveness of radiology reporting using audio multimodal large language models (LLMs) compared to conventional reporting with speech recognition software. We hypothesized that providing minimal audio input would enable a multimodal LLM to generate complete radiological reports. MATERIALS AND METHODS: 480 reports from 80 retrospective multimodal imaging studies were reported by two board-certified radiologists using three workflows: conventional workflow (C-WF) with speech recognition software to generate findings and impressions separately and LLM-based workflow (LLM-WF) using the state-of-the-art LLMs GPT-4o and Claude Sonnet 3.5. Outcome measures included reporting time, corrections and personnel cost per report. Two radiologists assessed formal structure and report quality. Statistical analysis used ANOVA and Tukey's post hoc tests (pâ€‰&lt;â€‰0.05). RESULTS: LLM-WF significantly reduced reporting time (GPT-4o/Sonnet 3.5: 38.9â€‰sâ€‰Â±â€‰22.7â€‰s vs. C-WF: 88.0â€‰sâ€‰Â±â€‰60.9â€‰s, pâ€‰&lt;â€‰0.01), required fewer corrections (GPT-4o: 1.0â€‰Â±â€‰1.1, Sonnet 3.5: 0.9â€‰Â±â€‰1.0 vs. C-WF: 2.4â€‰Â±â€‰2.5, pâ€‰&lt;â€‰0.01), and lowered costs (GPT-4o: $2.3 Â± $1.4, Sonnet 3.5: $2.4 Â± $1.4 vs. C-WF: $3.0 Â± $2.1, pâ€‰&lt;â€‰0.01). Reports generated with Sonnet 3.5 were rated highest in quality, while GPT-4o and conventional reports showed no difference. CONCLUSION: Multimodal LLMs can generate high-quality radiology reports based solely on minimal audio input, with greater speed, fewer corrections, and reduced costs compared to conventional speech-based workflows. However, future implementation may involve licensing costs, and generalizability to broader clinical contexts warrants further evaluation. KEY POINTS: Question Comparing time, accuracy, cost, and report quality of reporting using audio input functionality of GPT-4o and Claude Sonnet 3.5 to conventional reporting with speech recognition. Findings Large language models enable radiological reporting via minimal audio input, reducing turnaround time and costs without quality loss compared to conventional reporting with speech recognition. Clinical relevance Large language model-based reporting from minimal audio input has the potential to improve efficiency and report quality, supporting more streamlined workflows in clinical radiology.

### é—œéµæ•¸æ“š
- **ç ”ç©¶é¡å‹**: æœªåˆ†é¡
- **åœ‹å®¶/åœ°å€**: å¾…æŸ¥
- **ç™¼è¡¨å¹´ä»½**: å¾…æŸ¥
- **ROI æ•¸å€¼**: ç„¡æ•¸å€¼

### æ ¸å¿ƒå‰µæ–°é»
æœ¬ç ”ç©¶çš„ä¸»è¦å‰µæ–°åœ¨æ–¼ï¼šé«˜

---

## âœï¸ ç¬¬äºŒå¼µï¼šParaphrase å¡

### ç ”ç©¶ç›®çš„èˆ‡æ–¹æ³•
æœ¬ç ”ç©¶èšç„¦æ–¼9é ˜åŸŸï¼Œæ—¨åœ¨æ¢è¨ AI æŠ€è¡“åœ¨é†«ç™‚å ´æ™¯ä¸­çš„æ‡‰ç”¨ã€‚

### ä¸»è¦è²¢ç»
ç ”ç©¶æå‡ºäº†é«˜ï¼Œç‚ºè‡¨åºŠå¯¦è¸æä¾›äº†æ–°çš„è§£æ±ºæ–¹æ¡ˆã€‚

### æŠ€è¡“ç‰¹é»
- æ‡‰ç”¨å ´æ™¯ï¼š9
- å‰µæ–°ç¨‹åº¦ï¼šè©•åˆ† é«˜/10
- æœŸåˆŠå½±éŸ¿ï¼šç™¼è¡¨æ–¼ æœªçŸ¥æœŸåˆŠ

---

## â“ ç¬¬ä¸‰å¼µï¼šå•ç­”å¡

### Q1: é€™é …ç ”ç©¶è§£æ±ºäº†ä»€éº¼å•é¡Œï¼Ÿ
A: æœ¬ç ”ç©¶é‡å°9é ˜åŸŸçš„æŒ‘æˆ°ï¼Œæå‡ºäº†åŸºæ–¼ AI çš„è§£æ±ºæ–¹æ¡ˆã€‚

### Q2: æ¡ç”¨äº†ä»€éº¼æŠ€è¡“æ–¹æ³•ï¼Ÿ
A: é«˜

### Q3: ç ”ç©¶çš„ä¸»è¦æˆæœæ˜¯ä»€éº¼ï¼Ÿ
A: ç ”ç©¶ç²å¾—äº† é«˜ åˆ†çš„å°ˆå®¶è©•åˆ†ï¼Œè­‰æ˜äº†å…¶åœ¨9é ˜åŸŸçš„æ‡‰ç”¨åƒ¹å€¼ã€‚

### Q4: æœ‰å“ªäº›å¯¦éš›æ‡‰ç”¨å ´æ™¯ï¼Ÿ
A: ä¸»è¦æ‡‰ç”¨æ–¼9ï¼Œå¯ç”¨æ–¼æ”¹å–„é†«ç™‚æœå‹™å“è³ªå’Œæ•ˆç‡ã€‚

---

## ğŸ¤” ç¬¬å››å¼µï¼šä¾‹å¤–å¡

### æ½›åœ¨é™åˆ¶
1. **ç ”ç©¶ç¯„åœ**: ç ”ç©¶è©•åˆ†ç‚º é«˜/10ï¼Œå¯èƒ½å­˜åœ¨æ”¹é€²ç©ºé–“
2. **åœ°å€å·®ç•°**: ç ”ç©¶ä¾†è‡ªå¾…æŸ¥ï¼Œå…¶ä»–åœ°å€é©ç”¨æ€§éœ€é©—è­‰
3. **ROI æ•¸æ“š**: ç„¡æ•¸å€¼ï¼Œç¶“æ¿Ÿæ•ˆç›Šè©•ä¼°å¯èƒ½ä¸å®Œæ•´

### éœ€è¦é€²ä¸€æ­¥æ¢è¨çš„å•é¡Œ
1. è©²æŠ€è¡“åœ¨ä¸åŒè¦æ¨¡é†«é™¢çš„é©ç”¨æ€§å¦‚ä½•ï¼Ÿ
2. é•·æœŸä½¿ç”¨çš„æ•ˆæœå’Œç©©å®šæ€§æ˜¯å¦ç¶“éé©—è­‰ï¼Ÿ
3. èˆ‡ç¾æœ‰ç³»çµ±æ•´åˆæ™‚å¯èƒ½é¢è‡¨å“ªäº›æŒ‘æˆ°ï¼Ÿ

### æ‰¹åˆ¤æ€§æ€è€ƒ
- **æŠ€è¡“æˆç†Ÿåº¦**: éœ€è¦è©•ä¼°å¾ç ”ç©¶åˆ°å¯¦éš›éƒ¨ç½²çš„è·é›¢
- **æˆæœ¬æ•ˆç›Š**: ç„¡æ•¸å€¼ï¼Œéœ€è¦æ›´è©³ç´°çš„ç¶“æ¿Ÿåˆ†æ
- **å€«ç†è€ƒé‡**: AI åœ¨9æ‡‰ç”¨æ™‚çš„å€«ç†å’Œéš±ç§å•é¡Œ
- **å¯æ¨å»£æ€§**: ç ”ç©¶çµæœåœ¨å…¶ä»–é†«ç™‚å ´æ™¯çš„é©ç”¨æ€§

---

## ğŸ“š åƒè€ƒè³‡è¨Š
- **PMID**: [40815310](https://pubmed.ncbi.nlm.nih.gov/40815310/)
- **DOI**: https://doi.org/10.1007/s00330-025-11929-y
- **æœŸåˆŠ**: æœªçŸ¥æœŸåˆŠ
