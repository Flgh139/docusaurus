---
sidebar_position: 57
---

# 文獻 57：A comprehensive evaluation of large language models for information extraction

**English Title**: A comprehensive evaluation of large language models for information extraction

**中文標題**: 大型語言模型信息提取的綜合評估
**PMID**: 40886641
**期刊**: Computers in biology and medicine
**評分**: 8.5
**應用領域**: 長期照護
**DOI**: https://doi.org/10.1016/j.compbiomed.2025.111013

---

## 📌 第一張：核心觀點卡

### 主要發現
全面LLM評估框架

### 文獻摘要（Abstract）
Despite rapid healthcare digitization, extracting information from unstructured electronic health records (EHRs), such as nursing notes, remains challenging due to inconsistencies and ambiguities in clinical documentation. Generative large language models (LLMs) have emerged as promising tools for automating information extraction (IE); however, their application in real-world clinical settings, such as residential aged care (RAC), is limited by critical gaps. Prior studies have often focused on structured EHR data and conventional evaluation metrics such as accuracy and F1 score, overlooking critical aspects like robustness, fairness, bias, and contextual relevance, particularly in unstructured clinical narratives. To address these gaps, this study develops a holistic evaluation framework for clinical IE from free-text nursing notes in the Australian RAC. We systematically evaluate 17 LLMs, including general-purpose and healthcare-specific variants (e.g., LLaMA, Mistral, Gemini, T5) across retrieval-augmented generation (RAG) frameworks and few-shot learning configurations (one-shot, three-shot, four-shot, five-shot). The evaluation focuses on two clinical IE tasks: named entity recognition (NER) and summarization. Results reveal LLaMA 3.1 achieved 88.58 % accuracy, 87.43 % F1 score in NER, 88.18 % F1 score, and 83.15 % relevance in summarization. However, robustness remained low (4.00 % for NER, 4.31 % for summarization) despite excellent fairness (99.9 %) and minimal bias (0.11 %) in both tasks. Further, healthcare-specific LLMs slightly outperform general models, and RAG-based approaches (LangChain, LlamaIndex) yield superior results. Task-specific optimal few-shot settings emerged: three-shot for NER and five-shot for summarization. This study provides a foundation for safely integrating generative AI into clinical decision support.

### 關鍵數據
- **研究類型**: 未分類
- **國家/地區**: 待查
- **發表年份**: 待查
- **ROI 數值**: 無數值

### 核心創新點
本研究的主要創新在於：全面LLM評估框架

---

## ✍️ 第二張：Paraphrase 卡

### 研究目的與方法
本研究聚焦於長期照護領域，旨在探討 AI 技術在醫療場景中的應用。

### 主要貢獻
研究提出了全面LLM評估框架，為臨床實踐提供了新的解決方案。

### 技術特點
- 應用場景：長期照護
- 創新程度：評分 8.5/10
- 期刊影響：發表於 Computers in biology and medicine

---

## ❓ 第三張：問答卡

### Q1: 這項研究解決了什麼問題？
A: 本研究針對長期照護領域的挑戰，提出了基於 AI 的解決方案。

### Q2: 採用了什麼技術方法？
A: 全面LLM評估框架

### Q3: 研究的主要成果是什麼？
A: 研究獲得了 8.5 分的專家評分，證明了其在長期照護領域的應用價值。

### Q4: 有哪些實際應用場景？
A: 主要應用於長期照護，可用於改善醫療服務品質和效率。

---

## 🤔 第四張：例外卡

### 潛在限制
1. **研究範圍**: 研究評分為 8.5/10，可能存在改進空間
2. **地區差異**: 研究來自待查，其他地區適用性需驗證
3. **ROI 數據**: 無數值，經濟效益評估可能不完整

### 需要進一步探討的問題
1. 該技術在不同規模醫院的適用性如何？
2. 長期使用的效果和穩定性是否經過驗證？
3. 與現有系統整合時可能面臨哪些挑戰？

### 批判性思考
- **技術成熟度**: 需要評估從研究到實際部署的距離
- **成本效益**: 無數值，需要更詳細的經濟分析
- **倫理考量**: AI 在長期照護應用時的倫理和隱私問題
- **可推廣性**: 研究結果在其他醫療場景的適用性

---

## 📚 參考資訊
- **PMID**: [40886641](https://pubmed.ncbi.nlm.nih.gov/40886641/)
- **DOI**: https://doi.org/10.1016/j.compbiomed.2025.111013
- **期刊**: Computers in biology and medicine
