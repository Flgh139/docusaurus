---
sidebar_position: 3
---

# 文獻 3：Simulated Reasoning and Self-Verification in Generalist Large Language Models for Psychiatric Diagnostic Performance

**English Title**: Simulated Reasoning and Self-Verification in Generalist Large Language Models for Psychiatric Diagnostic Performance

**中文標題**: 通用大型語言模型中的模擬推理與自我驗證用於精神病學診斷性能
**PMID**: 40963745
**期刊**: medRxiv : the preprint server for health sciences
**評分**: 8
**應用領域**: 精神科
**DOI**: https://doi.org/10.1101/2025.09.05.25335196

---

## 📌 第一張：核心觀點卡

### 主要發現
創新的推理token機制

### 文獻摘要（Abstract）
BACKGROUND: Large language models (LLMs) have rapidly garnered significant interest for application in psychiatry and behavioral health. However, recent studies have identified significant shortcomings and potential risks in the performance of LLM-based systems, complicating their application to psychiatric diagnosis. Two promising approaches to addressing these challenges and improving the efficacy of these models are simulated reasoning and self-verification, in which additional "reasoning tokens" are used to guide model output, either during or after inference. OBJECTIVES: We aimed to explore how the use of simulated reasoning (via the use of large reasoning models, or LRMs) and self-verification (via supplemental prompting) affect the psychiatric diagnostic performance of language models. METHODS: 106 case vignettes and associated diagnoses were extracted from the DSM-5-TR Clinical Cases book, with permission. An LLM and an LRM model were selected from each of the two vendors studied (OpenAI and Google). Two inference approaches were developed, a Basic approach that directly prompted models to provide diagnoses, and a Self-Verification approach that augmented the Basic approach with additional prompts. All case vignettes were processed by the four models and two approaches, and diagnostic performance was evaluated using the sensitivity and positive predictive value (PPV). Linear mixed effect models were used to test for significant differences between the vendors, model types, and inference approaches. RESULTS: All vignettes were successfully processed by each model and inference approach. Sensitivity ranged from 0.732 to 0.817, and PPV ranged from 0.534 to 0.779. The best overall performance was found in  CONCLUSIONS: We found that both simulated reasoning and self-verification yielded statistically significant improvements in the PPV, without significant differences in the sensitivity. The addition of the manually specified self-verification prompt improved the PPV even when simulated reasoning was used. This suggests that future efforts to apply language models in behavioral health may benefit from a combination of manually crafted reasoning prompts and automated simulated reasoning.

### 中文摘要
背景：大型語言模型（LLMs）在精神病學和行為健康應用方面迅速獲得廣泛關注。然而，最近的研究發現基於 LLM 系統的表現存在顯著缺陷和潛在風險，使其在精神病學診斷中的應用變得複雜。模擬推理和自我驗證是解決這些挑戰並提高模型效能的兩種有前景的方法，其中使用額外的「推理標記」在推論過程中或之後指導模型輸出。目標：我們旨在探討模擬推理（透過使用大型推理模型或 LRMs）和自我驗證（透過補充提示）如何影響語言模型的精神病學診斷性能。方法：經許可從 DSM-5-TR 臨床案例書中提取了 106 個案例情境及相關診斷。從研究的兩個供應商（OpenAI 和 Google）各選擇一個 LLM 和一個 LRM 模型。開發了兩種推論方法：直接提示模型提供診斷的基本方法，以及使用額外提示增強基本方法的自我驗證方法。所有案例情境由四個模型和兩種方法處理，診斷性能使用敏感度和陽性預測值（PPV）評估。使用線性混合效應模型檢驗供應商、模型類型和推論方法之間的顯著差異。結果：每個模型和推論方法均成功處理所有情境。敏感度範圍從 0.732 到 0.817，PPV 範圍從 0.534 到 0.779。結論：我們發現模擬推理和自我驗證都在 PPV 方面產生統計上顯著的改善，而敏感度沒有顯著差異。即使使用模擬推理時，手動指定的自我驗證提示的添加也改善了 PPV。這表明未來在行為健康領域應用語言模型的努力可能受益於手動製作的推理提示與自動化模擬推理的結合。

### 關鍵數據
- **研究類型**: 未分類
- **國家/地區**: 待查
- **發表年份**: 待查
- **ROI 數值**: 無數值

### 核心創新點
本研究的主要創新在於：創新的推理token機制

---

## ✍️ 第二張：Paraphrase 卡

### 研究目的與方法
本研究聚焦於精神科領域，旨在探討 AI 技術在醫療場景中的應用。

### 主要貢獻
研究提出了創新的推理token機制，為臨床實踐提供了新的解決方案。

### 技術特點
- 應用場景：精神科
- 創新程度：評分 8/10
- 期刊影響：發表於 medRxiv : the preprint server for health sciences

---

## ❓ 第三張：問答卡

### Q1: 這項研究解決了什麼問題？
A: 本研究針對精神科領域的挑戰，提出了基於 AI 的解決方案。

### Q2: 採用了什麼技術方法？
A: 創新的推理token機制

### Q3: 研究的主要成果是什麼？
A: 研究獲得了 8 分的專家評分，證明了其在精神科領域的應用價值。

### Q4: 有哪些實際應用場景？
A: 主要應用於精神科，可用於改善醫療服務品質和效率。

---

## 🤔 第四張：例外卡

### 潛在限制
1. **研究範圍**: 研究評分為 8/10，可能存在改進空間
2. **地區差異**: 研究來自待查，其他地區適用性需驗證
3. **ROI 數據**: 無數值，經濟效益評估可能不完整

### 需要進一步探討的問題
1. 該技術在不同規模醫院的適用性如何？
2. 長期使用的效果和穩定性是否經過驗證？
3. 與現有系統整合時可能面臨哪些挑戰？

### 批判性思考
- **技術成熟度**: 需要評估從研究到實際部署的距離
- **成本效益**: 無數值，需要更詳細的經濟分析
- **倫理考量**: AI 在精神科應用時的倫理和隱私問題
- **可推廣性**: 研究結果在其他醫療場景的適用性

---

## 📚 參考資訊
- **PMID**: [40963745](https://pubmed.ncbi.nlm.nih.gov/40963745/)
- **DOI**: https://doi.org/10.1101/2025.09.05.25335196
- **期刊**: medRxiv : the preprint server for health sciences
