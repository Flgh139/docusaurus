---
sidebar_position: 68
---

# æ–‡ç» 68ï¼šOctascope A Lightweight Pre-Trained Model for Optical Coherence Tomography

**English Title**: Octascope A Lightweight Pre-Trained Model for Optical Coherence Tomography

**ä¸­æ–‡æ¨™é¡Œ**: Octascopeï¼šç”¨æ–¼å…‰å­¸ç›¸å¹²æ–·å±¤æƒæçš„è¼•é‡ç´šé è¨“ç·´æ¨¡å‹
**PMID**: 40874077
**æœŸåˆŠ**: IEEE access
**è©•åˆ†**: 8.0
**æ‡‰ç”¨é ˜åŸŸ**: çœ¼ç§‘/å…§ç§‘
**DOI**: https://doi.org/10.1109/access.2025.3595838

---

## ğŸ“Œ ç¬¬ä¸€å¼µï¼šæ ¸å¿ƒè§€é»å¡

### ä¸»è¦ç™¼ç¾
OCTå°ˆç”¨è¼•é‡ç´šæ¨¡å‹

### æ–‡ç»æ‘˜è¦ï¼ˆAbstractï¼‰
Optical coherence tomography (OCT) imaging enables high resolution visualization of sub-surface tissue microstructures. However, OCT image analysis using deep learning is hampered by limited diverse training data to meet performance requirements and high inference latency for real-time applications. To address these challenges, we developed Octascope, a lightweight domain-specific convolutional neural network (CNN) - based model designed for OCT image analysis. Octascope was pre-trained using a curriculum learning approach, which involves sequential training, first on natural images (ImageNet), then on OCT images from retinal, abdominal, and renal tissues, to progressively acquire transferable knowledge. This multi-domain pre-training enables Octascope to generalize across varied tissue types. In two downstream tasks, Octascope demonstrated notable improvements in predictive accuracy compared to alternative approaches. In the epidural tissue detection task, our method surpassed single-task learning with fine-tuning by 9.13% and OCT-specific transfer learning by 5.95% in accuracy. Octascope outperformed VGG16 and ResNet50 by 5.36% and 6.66% in a retinal diagnosis task, respectively. In comparison to a Transformer-based OCT foundation model - RETFound, Octascope delivered 2 to 4.4 times faster inference speed with slightly better predictive accuracies in both downstream tasks. Octascope represented a significant advancement for OCT image analysis by providing an effective balance between computational efficiency and diagnostic accuracy for real-time clinical applications.

### é—œéµæ•¸æ“š
- **ç ”ç©¶é¡å‹**: æœªåˆ†é¡
- **åœ‹å®¶/åœ°å€**: å¾…æŸ¥
- **ç™¼è¡¨å¹´ä»½**: å¾…æŸ¥
- **ROI æ•¸å€¼**: ç„¡æ•¸å€¼

### æ ¸å¿ƒå‰µæ–°é»
æœ¬ç ”ç©¶çš„ä¸»è¦å‰µæ–°åœ¨æ–¼ï¼šOCTå°ˆç”¨è¼•é‡ç´šæ¨¡å‹

---

## âœï¸ ç¬¬äºŒå¼µï¼šParaphrase å¡

### ç ”ç©¶ç›®çš„èˆ‡æ–¹æ³•
æœ¬ç ”ç©¶èšç„¦æ–¼çœ¼ç§‘/å…§ç§‘é ˜åŸŸï¼Œæ—¨åœ¨æ¢è¨ AI æŠ€è¡“åœ¨é†«ç™‚å ´æ™¯ä¸­çš„æ‡‰ç”¨ã€‚

### ä¸»è¦è²¢ç»
ç ”ç©¶æå‡ºäº†OCTå°ˆç”¨è¼•é‡ç´šæ¨¡å‹ï¼Œç‚ºè‡¨åºŠå¯¦è¸æä¾›äº†æ–°çš„è§£æ±ºæ–¹æ¡ˆã€‚

### æŠ€è¡“ç‰¹é»
- æ‡‰ç”¨å ´æ™¯ï¼šçœ¼ç§‘/å…§ç§‘
- å‰µæ–°ç¨‹åº¦ï¼šè©•åˆ† 8.0/10
- æœŸåˆŠå½±éŸ¿ï¼šç™¼è¡¨æ–¼ IEEE access

---

## â“ ç¬¬ä¸‰å¼µï¼šå•ç­”å¡

### Q1: é€™é …ç ”ç©¶è§£æ±ºäº†ä»€éº¼å•é¡Œï¼Ÿ
A: æœ¬ç ”ç©¶é‡å°çœ¼ç§‘/å…§ç§‘é ˜åŸŸçš„æŒ‘æˆ°ï¼Œæå‡ºäº†åŸºæ–¼ AI çš„è§£æ±ºæ–¹æ¡ˆã€‚

### Q2: æ¡ç”¨äº†ä»€éº¼æŠ€è¡“æ–¹æ³•ï¼Ÿ
A: OCTå°ˆç”¨è¼•é‡ç´šæ¨¡å‹

### Q3: ç ”ç©¶çš„ä¸»è¦æˆæœæ˜¯ä»€éº¼ï¼Ÿ
A: ç ”ç©¶ç²å¾—äº† 8.0 åˆ†çš„å°ˆå®¶è©•åˆ†ï¼Œè­‰æ˜äº†å…¶åœ¨çœ¼ç§‘/å…§ç§‘é ˜åŸŸçš„æ‡‰ç”¨åƒ¹å€¼ã€‚

### Q4: æœ‰å“ªäº›å¯¦éš›æ‡‰ç”¨å ´æ™¯ï¼Ÿ
A: ä¸»è¦æ‡‰ç”¨æ–¼çœ¼ç§‘/å…§ç§‘ï¼Œå¯ç”¨æ–¼æ”¹å–„é†«ç™‚æœå‹™å“è³ªå’Œæ•ˆç‡ã€‚

---

## ğŸ¤” ç¬¬å››å¼µï¼šä¾‹å¤–å¡

### æ½›åœ¨é™åˆ¶
1. **ç ”ç©¶ç¯„åœ**: ç ”ç©¶è©•åˆ†ç‚º 8.0/10ï¼Œå¯èƒ½å­˜åœ¨æ”¹é€²ç©ºé–“
2. **åœ°å€å·®ç•°**: ç ”ç©¶ä¾†è‡ªå¾…æŸ¥ï¼Œå…¶ä»–åœ°å€é©ç”¨æ€§éœ€é©—è­‰
3. **ROI æ•¸æ“š**: ç„¡æ•¸å€¼ï¼Œç¶“æ¿Ÿæ•ˆç›Šè©•ä¼°å¯èƒ½ä¸å®Œæ•´

### éœ€è¦é€²ä¸€æ­¥æ¢è¨çš„å•é¡Œ
1. è©²æŠ€è¡“åœ¨ä¸åŒè¦æ¨¡é†«é™¢çš„é©ç”¨æ€§å¦‚ä½•ï¼Ÿ
2. é•·æœŸä½¿ç”¨çš„æ•ˆæœå’Œç©©å®šæ€§æ˜¯å¦ç¶“éé©—è­‰ï¼Ÿ
3. èˆ‡ç¾æœ‰ç³»çµ±æ•´åˆæ™‚å¯èƒ½é¢è‡¨å“ªäº›æŒ‘æˆ°ï¼Ÿ

### æ‰¹åˆ¤æ€§æ€è€ƒ
- **æŠ€è¡“æˆç†Ÿåº¦**: éœ€è¦è©•ä¼°å¾ç ”ç©¶åˆ°å¯¦éš›éƒ¨ç½²çš„è·é›¢
- **æˆæœ¬æ•ˆç›Š**: ç„¡æ•¸å€¼ï¼Œéœ€è¦æ›´è©³ç´°çš„ç¶“æ¿Ÿåˆ†æ
- **å€«ç†è€ƒé‡**: AI åœ¨çœ¼ç§‘/å…§ç§‘æ‡‰ç”¨æ™‚çš„å€«ç†å’Œéš±ç§å•é¡Œ
- **å¯æ¨å»£æ€§**: ç ”ç©¶çµæœåœ¨å…¶ä»–é†«ç™‚å ´æ™¯çš„é©ç”¨æ€§

---

## ğŸ“š åƒè€ƒè³‡è¨Š
- **PMID**: [40874077](https://pubmed.ncbi.nlm.nih.gov/40874077/)
- **DOI**: https://doi.org/10.1109/access.2025.3595838
- **æœŸåˆŠ**: IEEE access
