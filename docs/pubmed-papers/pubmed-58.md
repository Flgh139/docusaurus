---
sidebar_position: 58
---

# 文獻 58：Personalized health monitoring using explainable AI bridging trust in predictive healthcare

**English Title**: Personalized health monitoring using explainable AI bridging trust in predictive healthcare

**中文標題**: 使用可解釋 AI 的個性化健康監測：在預測性醫療保健中建立信任
**PMID**: 40883377
**期刊**: Scientific reports
**評分**: 9.0
**應用領域**: 重症監護
**DOI**: https://doi.org/10.1038/s41598-025-15867-z

---

## 📌 第一張：核心觀點卡

### 主要發現
個人化可解釋AI

### 文獻摘要（Abstract）
AI has propelled the potential for moving toward personalized health and early prediction of diseases. Unfortunately, a significant limitation of many of these deep learning models is that they are not interpretable, restricting their clinical utility and undermining trust by clinicians. However, all existing methods are non-informative because they report generic or post-hoc explanations, and few or none support patient-specific, accurate, individualized patient-level explanations. Furthermore, existing approaches are often restricted to static, limited-domain datasets and are not generalizable across various healthcare scenarios. To tackle these problems, we propose a new deep learning approach called PersonalCareNet for personalized health monitoring based on the MIMIC-III clinical dataset. Our system jointly models convolutional neural networks with attention (CHARMS) and employs SHAP (Shapley Additive exPlanations) to obtain global and patient-specific model interpretability. We believe the model, enabled to leverage many clinical features, would offer clinically interpretable insights into the contribution of features while supporting real-time risk prediction, thus increasing transparency and instilling clinically-oriented trust in the model. We provide an extensive evaluation that shows PersonalCareNet achieves 97.86% accuracy, exceeding multiple notable SoTA healthcare risk prediction models. Explainability at Both Local and Global Level The framework offers explainability at local (using various matrix heatmaps for diagnosing models, such as force plots, SHAP summary visualizations, and confusion matrix-based diagnostics) and also at a global level through feature importance plots and Top-N list visualizations. As a result, we show quantitative results, demonstrating that much of the improvement can be achieved without paying a high price for interpretability. We have proposed a cost-effective and systematic approach as an AI-based platform that is scalable, accurate, transparent, and interpretable for critical care and personalized diagnostics. PersonalCareNet, by filling the void between performance and interpretability, promises a significant advancement in the field of reliable and clinically validated predictive healthcare AI. The design allows for additional extension to multiple data types and real-time deployment at the edge, creating a broader impact and adaptability.

### 關鍵數據
- **研究類型**: 未分類
- **國家/地區**: 待查
- **發表年份**: 待查
- **ROI 數值**: 無數值

### 核心創新點
本研究的主要創新在於：個人化可解釋AI

---

## ✍️ 第二張：Paraphrase 卡

### 研究目的與方法
本研究聚焦於重症監護領域，旨在探討 AI 技術在醫療場景中的應用。

### 主要貢獻
研究提出了個人化可解釋AI，為臨床實踐提供了新的解決方案。

### 技術特點
- 應用場景：重症監護
- 創新程度：評分 9.0/10
- 期刊影響：發表於 Scientific reports

---

## ❓ 第三張：問答卡

### Q1: 這項研究解決了什麼問題？
A: 本研究針對重症監護領域的挑戰，提出了基於 AI 的解決方案。

### Q2: 採用了什麼技術方法？
A: 個人化可解釋AI

### Q3: 研究的主要成果是什麼？
A: 研究獲得了 9.0 分的專家評分，證明了其在重症監護領域的應用價值。

### Q4: 有哪些實際應用場景？
A: 主要應用於重症監護，可用於改善醫療服務品質和效率。

---

## 🤔 第四張：例外卡

### 潛在限制
1. **研究範圍**: 研究評分為 9.0/10，可能存在改進空間
2. **地區差異**: 研究來自待查，其他地區適用性需驗證
3. **ROI 數據**: 無數值，經濟效益評估可能不完整

### 需要進一步探討的問題
1. 該技術在不同規模醫院的適用性如何？
2. 長期使用的效果和穩定性是否經過驗證？
3. 與現有系統整合時可能面臨哪些挑戰？

### 批判性思考
- **技術成熟度**: 需要評估從研究到實際部署的距離
- **成本效益**: 無數值，需要更詳細的經濟分析
- **倫理考量**: AI 在重症監護應用時的倫理和隱私問題
- **可推廣性**: 研究結果在其他醫療場景的適用性

---

## 📚 參考資訊
- **PMID**: [40883377](https://pubmed.ncbi.nlm.nih.gov/40883377/)
- **DOI**: https://doi.org/10.1038/s41598-025-15867-z
- **期刊**: Scientific reports
