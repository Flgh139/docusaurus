---
sidebar_position: 58
---

# æ–‡ç» 58ï¼šPersonalized health monitoring using explainable AI bridging trust in predictive healthcare

**English Title**: Personalized health monitoring using explainable AI bridging trust in predictive healthcare

**ä¸­æ–‡æ¨™é¡Œ**: ä½¿ç”¨å¯è§£é‡‹ AI çš„å€‹æ€§åŒ–å¥åº·ç›£æ¸¬ï¼šåœ¨é æ¸¬æ€§é†«ç™‚ä¿å¥ä¸­å»ºç«‹ä¿¡ä»»
**PMID**: 40883377
**æœŸåˆŠ**: Scientific reports
**è©•åˆ†**: 9.0
**æ‡‰ç”¨é ˜åŸŸ**: é‡ç—‡ç›£è­·
**DOI**: https://doi.org/10.1038/s41598-025-15867-z

---

## ğŸ“Œ ç¬¬ä¸€å¼µï¼šæ ¸å¿ƒè§€é»å¡

### ä¸»è¦ç™¼ç¾
å€‹äººåŒ–å¯è§£é‡‹AI

### æ–‡ç»æ‘˜è¦ï¼ˆAbstractï¼‰
AI has propelled the potential for moving toward personalized health and early prediction of diseases. Unfortunately, a significant limitation of many of these deep learning models is that they are not interpretable, restricting their clinical utility and undermining trust by clinicians. However, all existing methods are non-informative because they report generic or post-hoc explanations, and few or none support patient-specific, accurate, individualized patient-level explanations. Furthermore, existing approaches are often restricted to static, limited-domain datasets and are not generalizable across various healthcare scenarios. To tackle these problems, we propose a new deep learning approach called PersonalCareNet for personalized health monitoring based on the MIMIC-III clinical dataset. Our system jointly models convolutional neural networks with attention (CHARMS) and employs SHAP (Shapley Additive exPlanations) to obtain global and patient-specific model interpretability. We believe the model, enabled to leverage many clinical features, would offer clinically interpretable insights into the contribution of features while supporting real-time risk prediction, thus increasing transparency and instilling clinically-oriented trust in the model. We provide an extensive evaluation that shows PersonalCareNet achieves 97.86% accuracy, exceeding multiple notable SoTA healthcareâ€‚risk prediction models. Explainability at Both Local and Global Level The framework offers explainability at local (using various matrix heatmaps for diagnosing models, such as force plots, SHAP summary visualizations, and confusion matrix-based diagnostics) and also at a global level through feature importance plots and Top-N list visualizations. As a result, we show quantitative results, demonstrating that much of the improvement can be achieved without paying a high price for interpretability. We have proposed a cost-effective and systematic approach as an AI-based platform that is scalable, accurate, transparent, and interpretable for critical care and personalized diagnostics. PersonalCareNet, by filling the void between performance and interpretability, promises a significant advancement in the field of reliable and clinically validated predictive healthcare AI. The design allows for additional extension to multiple data types and real-time deployment at the edge, creating a broader impact and adaptability.

### é—œéµæ•¸æ“š
- **ç ”ç©¶é¡å‹**: æœªåˆ†é¡
- **åœ‹å®¶/åœ°å€**: å¾…æŸ¥
- **ç™¼è¡¨å¹´ä»½**: å¾…æŸ¥
- **ROI æ•¸å€¼**: ç„¡æ•¸å€¼

### æ ¸å¿ƒå‰µæ–°é»
æœ¬ç ”ç©¶çš„ä¸»è¦å‰µæ–°åœ¨æ–¼ï¼šå€‹äººåŒ–å¯è§£é‡‹AI

---

## âœï¸ ç¬¬äºŒå¼µï¼šParaphrase å¡

### ç ”ç©¶ç›®çš„èˆ‡æ–¹æ³•
æœ¬ç ”ç©¶èšç„¦æ–¼é‡ç—‡ç›£è­·é ˜åŸŸï¼Œæ—¨åœ¨æ¢è¨ AI æŠ€è¡“åœ¨é†«ç™‚å ´æ™¯ä¸­çš„æ‡‰ç”¨ã€‚

### ä¸»è¦è²¢ç»
ç ”ç©¶æå‡ºäº†å€‹äººåŒ–å¯è§£é‡‹AIï¼Œç‚ºè‡¨åºŠå¯¦è¸æä¾›äº†æ–°çš„è§£æ±ºæ–¹æ¡ˆã€‚

### æŠ€è¡“ç‰¹é»
- æ‡‰ç”¨å ´æ™¯ï¼šé‡ç—‡ç›£è­·
- å‰µæ–°ç¨‹åº¦ï¼šè©•åˆ† 9.0/10
- æœŸåˆŠå½±éŸ¿ï¼šç™¼è¡¨æ–¼ Scientific reports

---

## â“ ç¬¬ä¸‰å¼µï¼šå•ç­”å¡

### Q1: é€™é …ç ”ç©¶è§£æ±ºäº†ä»€éº¼å•é¡Œï¼Ÿ
A: æœ¬ç ”ç©¶é‡å°é‡ç—‡ç›£è­·é ˜åŸŸçš„æŒ‘æˆ°ï¼Œæå‡ºäº†åŸºæ–¼ AI çš„è§£æ±ºæ–¹æ¡ˆã€‚

### Q2: æ¡ç”¨äº†ä»€éº¼æŠ€è¡“æ–¹æ³•ï¼Ÿ
A: å€‹äººåŒ–å¯è§£é‡‹AI

### Q3: ç ”ç©¶çš„ä¸»è¦æˆæœæ˜¯ä»€éº¼ï¼Ÿ
A: ç ”ç©¶ç²å¾—äº† 9.0 åˆ†çš„å°ˆå®¶è©•åˆ†ï¼Œè­‰æ˜äº†å…¶åœ¨é‡ç—‡ç›£è­·é ˜åŸŸçš„æ‡‰ç”¨åƒ¹å€¼ã€‚

### Q4: æœ‰å“ªäº›å¯¦éš›æ‡‰ç”¨å ´æ™¯ï¼Ÿ
A: ä¸»è¦æ‡‰ç”¨æ–¼é‡ç—‡ç›£è­·ï¼Œå¯ç”¨æ–¼æ”¹å–„é†«ç™‚æœå‹™å“è³ªå’Œæ•ˆç‡ã€‚

---

## ğŸ¤” ç¬¬å››å¼µï¼šä¾‹å¤–å¡

### æ½›åœ¨é™åˆ¶
1. **ç ”ç©¶ç¯„åœ**: ç ”ç©¶è©•åˆ†ç‚º 9.0/10ï¼Œå¯èƒ½å­˜åœ¨æ”¹é€²ç©ºé–“
2. **åœ°å€å·®ç•°**: ç ”ç©¶ä¾†è‡ªå¾…æŸ¥ï¼Œå…¶ä»–åœ°å€é©ç”¨æ€§éœ€é©—è­‰
3. **ROI æ•¸æ“š**: ç„¡æ•¸å€¼ï¼Œç¶“æ¿Ÿæ•ˆç›Šè©•ä¼°å¯èƒ½ä¸å®Œæ•´

### éœ€è¦é€²ä¸€æ­¥æ¢è¨çš„å•é¡Œ
1. è©²æŠ€è¡“åœ¨ä¸åŒè¦æ¨¡é†«é™¢çš„é©ç”¨æ€§å¦‚ä½•ï¼Ÿ
2. é•·æœŸä½¿ç”¨çš„æ•ˆæœå’Œç©©å®šæ€§æ˜¯å¦ç¶“éé©—è­‰ï¼Ÿ
3. èˆ‡ç¾æœ‰ç³»çµ±æ•´åˆæ™‚å¯èƒ½é¢è‡¨å“ªäº›æŒ‘æˆ°ï¼Ÿ

### æ‰¹åˆ¤æ€§æ€è€ƒ
- **æŠ€è¡“æˆç†Ÿåº¦**: éœ€è¦è©•ä¼°å¾ç ”ç©¶åˆ°å¯¦éš›éƒ¨ç½²çš„è·é›¢
- **æˆæœ¬æ•ˆç›Š**: ç„¡æ•¸å€¼ï¼Œéœ€è¦æ›´è©³ç´°çš„ç¶“æ¿Ÿåˆ†æ
- **å€«ç†è€ƒé‡**: AI åœ¨é‡ç—‡ç›£è­·æ‡‰ç”¨æ™‚çš„å€«ç†å’Œéš±ç§å•é¡Œ
- **å¯æ¨å»£æ€§**: ç ”ç©¶çµæœåœ¨å…¶ä»–é†«ç™‚å ´æ™¯çš„é©ç”¨æ€§

---

## ğŸ“š åƒè€ƒè³‡è¨Š
- **PMID**: [40883377](https://pubmed.ncbi.nlm.nih.gov/40883377/)
- **DOI**: https://doi.org/10.1038/s41598-025-15867-z
- **æœŸåˆŠ**: Scientific reports
