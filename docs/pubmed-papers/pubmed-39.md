---
sidebar_position: 39
---

# 文獻 39：Performance of generative AI across ENT tasks: A systematic review and meta-analysis

**English Title**: Performance of generative AI across ENT tasks: A systematic review and meta-analysis

**中文標題**: 生成式 AI 在耳鼻喉科任務中的表現：系統性綜述和統合分析
**PMID**: 40912131
**期刊**: Auris nasus larynx
**評分**: 8
**應用領域**: 住院/ENT科
**DOI**: https://doi.org/10.1016/j.anl.2025.08.010

---

## 📌 第一張：核心觀點卡

### 主要發現
ENT專科AI應用綜合評估

### 文獻摘要（Abstract）
OBJECTIVE: To systematically evaluate the diagnostic accuracy, educational utility, and communication potential of generative AI, particularly Large Language Models (LLMs) such as ChatGPT, in otolaryngology. DATA SOURCES: A comprehensive search of PubMed, Embase, Scopus, Web of Science, and IEEE Xplore identified English-language peer-reviewed studies from January 2022 to March 2025. REVIEW METHODS: Eligible studies evaluated text-based generative AI models used in otolaryngology. Two reviewers screened and assessed studies using JBI and QUADAS-2 tools. A random-effects meta-analysis was conducted on diagnostic accuracy outcomes, with subgroup analyses by task type and model version. RESULTS: Ninety-one studies were included; 61 reported quantitative outcomes. Of these, 43 provided diagnostic accuracy data across 59 model-task pairs. Pooled diagnostic accuracy was 72.7 % (95 % CI: 67.4-77.6 %; I² = 93.8 %). Accuracy was highest in education (83.0 %) and diagnostic imaging tasks (84.9 %), and lowest in clinical decision support (67.1 %). GPT-4 consistently outperformed GPT-3.5 across both education and CDS domains. Hallucinations and performance variability were noted in complex clinical reasoning tasks. CONCLUSION: Generative AI performs well in structured otolaryngology tasks, particularly education and communication. However, its inconsistent performance in clinical reasoning tasks limits standalone use. Future research should focus on hallucination mitigation, standardized evaluation, and prospective validation to guide safe clinical integration.

### 中文摘要
**目的**：系統性評估生成式 AI，特別是大型語言模型（LLMs）如 ChatGPT 在耳鼻喉科的診斷準確性、教育效用和溝通潛力。**數據來源**：對 PubMed、Embase、Scopus、Web of Science 和 IEEE Xplore 進行全面搜索，識別 2022 年 1 月至 2025 年 3 月的英文同行評審研究。**綜述方法**：符合條件的研究評估了在耳鼻喉科中使用的基於文本的生成式 AI 模型。兩名評審員使用 JBI 和 QUADAS-2 工具篩選和評估研究。對診斷準確性結果進行隨機效應統合分析，並按任務類型和模型版本進行亞組分析。**結果**：納入 91 項研究；61 項報告了量化結果。其中 43 項提供了 59 個模型任務對的診斷準確性數據。合併診斷準確率為 72.7%（95% CI：67.4-77.6%；I² = 93.8%）。教育任務（83.0%）和診斷影像任務（84.9%）的準確率最高，臨床決策支持（67.1%）最低。GPT-4 在教育和 CDS 領域均持續優於 GPT-3.5。在複雜臨床推理任務中注意到幻覺和性能變異性。**結論**：生成式 AI 在結構化耳鼻喉科任務中表現良好，特別是在教育和溝通方面。然而，其在臨床推理任務中的不一致表現限制了獨立使用。未來研究應聚焦於幻覺緩解、標準化評估和前瞻性驗證，以指導安全的臨床整合。

### 關鍵數據
- **研究類型**: 未分類
- **國家/地區**: 待查
- **發表年份**: 待查
- **ROI 數值**: 無數值

### 核心創新點
本研究的主要創新在於：ENT專科AI應用綜合評估

---

## ✍️ 第二張：Paraphrase 卡

### 研究目的與方法
本研究聚焦於住院/ENT科領域，旨在探討 AI 技術在醫療場景中的應用。

### 主要貢獻
研究提出了ENT專科AI應用綜合評估，為臨床實踐提供了新的解決方案。

### 技術特點
- 應用場景：住院/ENT科
- 創新程度：評分 8/10
- 期刊影響：發表於 Auris nasus larynx

---

## ❓ 第三張：問答卡

### Q1: 這項研究解決了什麼問題？
A: 本研究針對住院/ENT科領域的挑戰，提出了基於 AI 的解決方案。

### Q2: 採用了什麼技術方法？
A: ENT專科AI應用綜合評估

### Q3: 研究的主要成果是什麼？
A: 研究獲得了 8 分的專家評分，證明了其在住院/ENT科領域的應用價值。

### Q4: 有哪些實際應用場景？
A: 主要應用於住院/ENT科，可用於改善醫療服務品質和效率。

---

## 🤔 第四張：例外卡

### 潛在限制
1. **研究範圍**: 研究評分為 8/10，可能存在改進空間
2. **地區差異**: 研究來自待查，其他地區適用性需驗證
3. **ROI 數據**: 無數值，經濟效益評估可能不完整

### 需要進一步探討的問題
1. 該技術在不同規模醫院的適用性如何？
2. 長期使用的效果和穩定性是否經過驗證？
3. 與現有系統整合時可能面臨哪些挑戰？

### 批判性思考
- **技術成熟度**: 需要評估從研究到實際部署的距離
- **成本效益**: 無數值，需要更詳細的經濟分析
- **倫理考量**: AI 在住院/ENT科應用時的倫理和隱私問題
- **可推廣性**: 研究結果在其他醫療場景的適用性

---

## 📚 參考資訊
- **PMID**: [40912131](https://pubmed.ncbi.nlm.nih.gov/40912131/)
- **DOI**: https://doi.org/10.1016/j.anl.2025.08.010
- **期刊**: Auris nasus larynx
